{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472bd647",
   "metadata": {},
   "source": [
    "# Creating models and saving to an array \n",
    "Assuming the models are pre-set, and there is a folder named saved_models that holds all the models. Since the saved state dictionary were processed using GPU, speed up, the device should \n",
    "\n",
    "The get method will return arras wtith the model name, the models, and the optimizer.  The criterion is not included because the same one is used across all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e712c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458fbe42",
   "metadata": {},
   "source": [
    "### CNN\n",
    "This is the only model that we have to create, all the other models are pre-trained in the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28bb0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(64 * 56 * 56, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 1)  # Binary classification\n",
    "    )\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d9a41f",
   "metadata": {},
   "source": [
    "## Load models\n",
    "This class will take in the path to the folder that has all the models. Assuming all the file names are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc88ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class loadModels:\n",
    "    modelNames = ['cnn', 'resnet18_weights', 'resnet18', 'resnet50_weights', 'resnet50', 'vgg16_weights', 'vgg16', 'densenet121_weights', 'densenet121', 'efficientnet_b0_weights', 'efficientnet_b0']\n",
    "    models = []\n",
    "    optimizers = []\n",
    "\n",
    "    path = \"\"\n",
    "    device = \"\"\n",
    "    def __init__(self, path, device):\n",
    "        self.path = path\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def get_files_in_folder(self, folder_path):\n",
    "        # Check if the provided path is a valid directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            for entry in os.listdir(folder_path):\n",
    "                full_path = os.path.join(folder_path, entry)\n",
    "                # Check if the entry is a file\n",
    "                if os.path.isfile(full_path):\n",
    "                    entry = self.remove_file_extension(entry)\n",
    "                    self.modelNames.append(entry)\n",
    "        else:\n",
    "            print(f\"Error: '{folder_path}' is not a valid directory.\")\n",
    "    \n",
    "    def remove_file_extension(self, filepath):\n",
    "        filename_without_extension, _ = os.path.splitext(filepath)\n",
    "        return filename_without_extension\n",
    "    \n",
    "    def load_models(self):\n",
    "        # Load CNN model\n",
    "        modelCNN = cnn_model().to(self.device)\n",
    "        optimizerCNN = optim.SGD(cnn_model().parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "        checkpointCNN = torch.load(os.path.join(self.path, \"cnn.pth\"), map_location=self.device)\n",
    "        modelCNN.load_state_dict(checkpointCNN['model_state_dict'])\n",
    "        optimizerCNN.load_state_dict(checkpointCNN['optimizer_state_dict'])\n",
    "        self.models.append(modelCNN)\n",
    "        self.optimizers.append(optimizerCNN)\n",
    "        \n",
    "        # Load ResNet18 with weights\n",
    "        modelResNet18Wts = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).to(self.device)\n",
    "        num_ftrs = modelResNet18Wts.fc.in_features\n",
    "\n",
    "        for param in modelResNet18Wts.parameters():\n",
    "            param.requires_grad = False\n",
    "        modelResNet18Wts.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "        \n",
    "        optimizerResNet18Wts = optim.SGD(modelResNet18Wts.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "        optimizerResNet18Wts.step()\n",
    "        \n",
    "        checkpointResNet18Wts = torch.load(os.path.join(self.path, \"resnet18_weights.pth\"), map_location=self.device)\n",
    "        modelResNet18Wts.load_state_dict(checkpointResNet18Wts['model_state_dict'])\n",
    "        optimizerResNet18Wts.load_state_dict(checkpointResNet18Wts['optimizer_state_dict'])\n",
    "        self.models.append(modelResNet18Wts)\n",
    "        self.optimizers.append(optimizerResNet18Wts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Load ResNet18 without weights\n",
    "        modelResNet18 = models.resnet18().to(self.device)\n",
    "        num_ftrs = modelResNet18.fc.in_features\n",
    "\n",
    "        for param in modelResNet18.parameters():\n",
    "            param.requires_grad = False\n",
    "        modelResNet18.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "        optimizerResNet18 = optim.SGD(modelResNet18.fc.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "        checkpointResNet18 = torch.load(os.path.join(self.path, \"resnet18.pth\"), map_location=self.device)\n",
    "        modelResNet18.load_state_dict(checkpointResNet18['model_state_dict'])\n",
    "        optimizerResNet18.load_state_dict(checkpointResNet18['optimizer_state_dict'])\n",
    "        self.models.append(modelResNet18)\n",
    "        self.optimizers.append(optimizerResNet18)\n",
    "\n",
    "        # Load ResNet50 with weights\n",
    "        modelResNet50Wts = models.resnet50(weights=models.ResNet50_Weights.DEFAULT).to(self.device)\n",
    "        num_ftrs = modelResNet50Wts.fc.in_features\n",
    "\n",
    "        for param in modelResNet50Wts.parameters():\n",
    "            param.requires_grad = False\n",
    "        modelResNet50Wts.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "        optimizerResNet50Wts = optim.SGD(modelResNet50Wts.fc.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "        checkpointResNet50Wts = torch.load(os.path.join(self.path, \"resnet50_weights.pth\"), map_location=self.device)\n",
    "        modelResNet50Wts.load_state_dict(checkpointResNet50Wts['model_state_dict'])\n",
    "        optimizerResNet50Wts.load_state_dict(checkpointResNet50Wts['optimizer_state_dict'])\n",
    "        self.models.append(modelResNet50Wts)\n",
    "        self.optimizers.append(optimizerResNet50Wts)\n",
    "\n",
    "        # Load ResNet50 without weights\n",
    "        modelResNet50 = models.resnet50().to(self.device)\n",
    "        num_ftrs = modelResNet50.fc.in_features\n",
    "\n",
    "        for param in modelResNet50.parameters():\n",
    "            param.requires_grad = False\n",
    "        modelResNet50.fc = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "        optimizerResNet50 = optim.SGD(modelResNet50.fc.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "        checkpointResNet50 = torch.load(os.path.join(self.path, \"resnet50.pth\"), map_location=self.device)\n",
    "        modelResNet50.load_state_dict(checkpointResNet50['model_state_dict'])\n",
    "        optimizerResNet50.load_state_dict(checkpointResNet50['optimizer_state_dict'])\n",
    "        self.models.append(modelResNet50)\n",
    "        self.optimizers.append(optimizerResNet50)\n",
    "\n",
    "        # Load VGG16 with weights\n",
    "        modelVGG16Wts = models.vgg16(weights=models.VGG16_Weights.DEFAULT).to(self.device)\n",
    "\n",
    "        for param in modelVGG16Wts.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        num_features = modelVGG16Wts.classifier[6].in_features\n",
    "        features = list(modelVGG16Wts.classifier.children())[:-1]\n",
    "        features.extend([nn.Linear(num_features, 1)])  # Binary classification\n",
    "        modelVGG16Wts.classifier = nn.Sequential(*features)\n",
    "\n",
    "        modelVGG16Wts.classifier[6] = nn.Linear(num_ftrs, 1)  # Binary classification\n",
    "        optimizerVGG16Wts = optim.SGD(modelVGG16Wts.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "        checkpointVGG16Wts = torch.load(os.path.join(self.path, \"vgg16_weights.pth\"), map_location=self.device)\n",
    "        modelVGG16Wts.load_state_dict(checkpointVGG16Wts['model_state_dict'])\n",
    "        optimizerVGG16Wts.load_state_dict(checkpointVGG16Wts['optimizer_state_dict'])\n",
    "        self.models.append(modelVGG16Wts)\n",
    "        self.optimizers.append(optimizerVGG16Wts)\n",
    "\n",
    "        # Load VGG16 without weights\n",
    "        modelVGG16 = models.vgg16().to(self.device)\n",
    "        \n",
    "        for param in modelVGG16.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        num_features = modelVGG16.classifier[6].in_features\n",
    "        features = list(modelVGG16.classifier.children())[:-1]\n",
    "        features.extend([nn.Linear(num_features, 1)])  # Binary classification\n",
    "        modelVGG16.classifier = nn.Sequential(*features)\n",
    "\n",
    "        optimizerVGG16 = optim.SGD(modelVGG16.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "        \n",
    "        checkpointVGG16 = torch.load(os.path.join(self.path, \"vgg16.pth\"), map_location=self.device)\n",
    "        modelVGG16.load_state_dict(checkpointVGG16['model_state_dict'])\n",
    "        optimizerVGG16.load_state_dict(checkpointVGG16['optimizer_state_dict'])\n",
    "        self.models.append(modelVGG16)\n",
    "        self.optimizers.append(optimizerVGG16)\n",
    "\n",
    "        # Load DenseNet121 with weights\n",
    "        modelDensenetWts = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT).to(self.device)\n",
    "        num_ftrs = modelDensenetWts.classifier.in_features\n",
    "\n",
    "        for param in modelDensenetWts.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        modelDensenetWts.classifier = nn.Linear(num_ftrs, 2)  # Binary classification\n",
    "        optimizerDensenetWts = optim.SGD(modelDensenetWts.classifier.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "        checkpointDensenetWts = torch.load(os.path.join(self.path, \"densenet121_weights.pth\"), map_location=self.device)\n",
    "        modelDensenetWts.load_state_dict(checkpointDensenetWts['model_state_dict'])\n",
    "        optimizerDensenetWts.load_state_dict(checkpointDensenetWts['optimizer_state_dict'])\n",
    "        self.models.append(modelDensenetWts)\n",
    "        self.optimizers.append(optimizerDensenetWts)\n",
    "\n",
    "        # Load DenseNet121 without weights\n",
    "        modelDensenet = models.densenet121().to(self.device)\n",
    "        num_ftrs = modelDensenet.classifier.in_features\n",
    "\n",
    "        for param in modelDensenet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        modelDensenet.classifier = nn.Linear(num_ftrs, 2)  # Binary classification\n",
    "        optimizerDensenet = optim.SGD(modelDensenet.classifier.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "        checkpointDensenet = torch.load(os.path.join(self.path, \"densenet121.pth\"), map_location=self.device)\n",
    "        modelDensenet.load_state_dict(checkpointDensenet['model_state_dict'])\n",
    "        optimizerDensenet.load_state_dict(checkpointDensenet['optimizer_state_dict'])\n",
    "        self.models.append(modelDensenet)\n",
    "        self.optimizers.append(optimizerDensenet)\n",
    "\n",
    "        # Load EfficientNet_B0 with weights\n",
    "        modelEfficientNetWts = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT).to(self.device)\n",
    "        num_ftrs = modelEfficientNetWts.classifier[1].in_features\n",
    "\n",
    "        for param in modelEfficientNetWts.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        modelEfficientNetWts.classifier[1] = nn.Linear(num_ftrs, 2)  # Binary classification\n",
    "        optimizerEfficientNetWts = optim.SGD(modelEfficientNetWts.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "        checkpointEfficientNetWts = torch.load(os.path.join(self.path, \"efficientnet_b0_weights.pth\"), map_location=self.device)\n",
    "        modelEfficientNetWts.load_state_dict(checkpointEfficientNetWts['model_state_dict'])\n",
    "        optimizerEfficientNetWts.load_state_dict(checkpointEfficientNetWts['optimizer_state_dict'])\n",
    "        self.models.append(modelEfficientNetWts)\n",
    "        self.optimizers.append(optimizerEfficientNetWts)\n",
    "\n",
    "        # Load EfficientNet_B0 without weights\n",
    "        modelEfficientNet = models.efficientnet_b0().to(self.device)\n",
    "        num_ftrs = modelEfficientNet.classifier[1].in_features\n",
    "\n",
    "        for param in modelEfficientNet.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        modelEfficientNet.classifier[1] = nn.Linear(num_ftrs, 2)  # Binary classification\n",
    "        optimizerEfficientNet = optim.SGD(modelEfficientNet.parameters(), lr=0.001, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "        checkpointEfficientNet = torch.load(os.path.join(self.path, \"efficientnet_b0.pth\"), map_location=self.device)\n",
    "        modelEfficientNet.load_state_dict(checkpointEfficientNet['model_state_dict'])\n",
    "        optimizerEfficientNet.load_state_dict(checkpointEfficientNet['optimizer_state_dict'])\n",
    "        self.models.append(modelEfficientNet)\n",
    "        self.optimizers.append(optimizerEfficientNet)\n",
    "\n",
    "    def get_models(self):\n",
    "        return self.modelNames, self.models, self.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c7c081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon GPU\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using Apple Silicon GPU\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0115966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadAllModels = loadModels(\"/Users/vky/Documents/GitHub/CSC871_FinalProject_SFSU_Fall2025/saved_models\", torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d81bda9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "loaded state dict contains a parameter group that doesn't match the size of optimizer's group",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mloadAllModels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mloadModels.load_models\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     64\u001b[39m checkpointResNet18 = torch.load(os.path.join(\u001b[38;5;28mself\u001b[39m.path, \u001b[33m\"\u001b[39m\u001b[33mresnet18.pth\u001b[39m\u001b[33m\"\u001b[39m), map_location=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m     65\u001b[39m modelResNet18.load_state_dict(checkpointResNet18[\u001b[33m'\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[43moptimizerResNet18\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpointResNet18\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moptimizer_state_dict\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mself\u001b[39m.models.append(modelResNet18)\n\u001b[32m     68\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizers.append(optimizerResNet18)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/CSC871_FinalProject_SFSU_Fall2025/.venv/lib/python3.13/site-packages/torch/_compile.py:53\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     50\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive, wrapping=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     51\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/CSC871_FinalProject_SFSU_Fall2025/.venv/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py:1044\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1042\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m   1043\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1046\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/CSC871_FinalProject_SFSU_Fall2025/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:935\u001b[39m, in \u001b[36mOptimizer.load_state_dict\u001b[39m\u001b[34m(self, state_dict)\u001b[39m\n\u001b[32m    933\u001b[39m saved_lens = (\u001b[38;5;28mlen\u001b[39m(g[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m saved_groups)\n\u001b[32m    934\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(p_len != s_len \u001b[38;5;28;01mfor\u001b[39;00m p_len, s_len \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(param_lens, saved_lens)):\n\u001b[32m--> \u001b[39m\u001b[32m935\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    936\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded state dict contains a parameter group \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    937\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthat doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt match the size of optimizer\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms group\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    938\u001b[39m     )\n\u001b[32m    940\u001b[39m \u001b[38;5;66;03m# Update the state\u001b[39;00m\n\u001b[32m    941\u001b[39m id_map = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    942\u001b[39m     \u001b[38;5;28mzip\u001b[39m(\n\u001b[32m    943\u001b[39m         chain.from_iterable(g[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m saved_groups),\n\u001b[32m    944\u001b[39m         chain.from_iterable(g[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m groups),\n\u001b[32m    945\u001b[39m     )\n\u001b[32m    946\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: loaded state dict contains a parameter group that doesn't match the size of optimizer's group"
     ]
    }
   ],
   "source": [
    "loadAllModels.load_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
